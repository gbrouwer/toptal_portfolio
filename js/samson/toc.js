let toc_content = [
	'<li>' +
	'<a href="">1 - Foreword</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_001.html#1.1">1.1 - Another book on machine learning?</a></li>' +
	'<li><a href="chapter_001.html#1.2">1.2 - Concepts, abstractions, and intuitions</a></li>' +
	'<li><a href="chapter_001.html#1.3">1.3 – Outline</a></li>' +
	'<li><a href="chapter_001.html#1.4">1.4 - Examples and demos</a></li>' +
	'<li><a href="chapter_001.html#1.5">1.5 - Errata</a></li>' +
	'<li><a href="chapter_001.html#1.6">1.6 – References</a></li>' +
	'</ul>' +
	'</li>'];

toc_content.push(
	'<li>' +
	'<a href="#">2 - Definitions</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_002.html#2.1">2.1 - Introduction</a></li>' +
	'<li><a href="chapter_002.html#2.2">2.2 - Data Science</a></li>' +
	'<li><a href="chapter_002.html#2.3">2.3 - Artificial Intelligence</a></li>' +
	'<li><a href="chapter_002.html#2.4">2.4 – Machine Learning</a></li>' +
	'<li><a href="chapter_002.html#2.5">2.5 – User experience and design</a></li>' +
	'<li><a href="chapter_002.html#2.6">2.6 – Putting them together</a></li>' +
	'<li><a href="chapter_002.html#2.7">2.7 - Alternative definitions</a></li>' +
	'<li><a href="chapter_002.html#2.8">2.8 - References</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">3 - History of AI</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_003.html#3.1">3.1 - Mechanical Turk (1770)</a></li>' +
	'<li><a href="chapter_003.html#3.2">3.2 - Luigi Galvani (1780)</a></li>' +
	'<li><a href="chapter_003.html#3.3">3.3 - The Loom (1801)</a></li>' +
	'<li><a href="chapter_003.html#3.4">3.4 - Mary Shelleys Frankenstein (1818)</a></li>' +
	'<li><a href="chapter_003.html#3.5">3.5 - Modern Neuroscience (1860 – onward)</a></li>' +
	'<li><a href="chapter_003.html#3.6">3.6 - Alan Turing (1936)</a></li>' +
	'<li><a href="chapter_003.html#3.7">3.7 - Dartmouth Conference (1954)</a></li>' +
	'<li><a href="chapter_003.html#3.8">3.8 - Eliza (1966)</a></li>' +
	'<li><a href="chapter_003.html#3.9">3.9 - Diverging fields (1970)</a></li>' +
	'<li><a href="chapter_003.html#3.10">3.10 - AI becomes useful (1980)</a></li>' +
	'<li><a href="chapter_003.html#3.11">3.11 - A parallel timeline</a></li>' +
	'<li><a href="chapter_003.html#3.12">3.12 - Trouble in Paradise (the 1980s)</a></li>' +
	'<li><a href="chapter_003.html#3.13">3.13 - AI Winter (mid-80s)</a></li>' +
	'<li><a href="chapter_003.html#3.14">3.14 - Revival of AI - 1980s</a></li>' +
	'<li><a href="chapter_003.html#3.15">3.15 - Machine Learning as a statistical problem (1988)</a></li>' +
	'<li><a href="chapter_003.html#3.16">3.16 - Deep Blue (1997)</a></li>' +
	'<li><a href="chapter_003.html#3.17">3.17 - A New Era of Computing (the early 2010s)</a></li>' +
	'<li><a href="chapter_003.html#3.18">3.18 - Deep Belief Networks (the 2010s – onward)</a></li>' +
	'<li><a href="chapter_003.html#3.19">3.19 - Convolutional Neural Nets (the late 2010s)</a></li>' +
	'<li><a href="chapter_003.html#3.20">3.20 - 2020s</a></li>' +
	'<li><a href="chapter_003.html#3.21">3.21 – The Bottom Line, the singularity, and beyond</a></li>' +
	'<li><a href="chapter_003.html#3.22">3.22 - References</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">4 - Philosophy of AI</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_004.html#4.1">4.1 - Introduction</a></li>' +
	'<li><a href="chapter_004.html#4.2">4.2 - Intelligence and the Turing test</a></li>' +
	'<li><a href="chapter_004.html#4.3">4.3 - Biological Intelligence</a></li>' +
	'<li><a href="chapter_004.html#4.4">4.4 - Perception – detection, segmentation, localization, and recognition</a></li>' +
	'<li><a href="chapter_004.html#4.5">4.5 - Cognition - reasoning with concepts, unknowns, and probabilities</a></li>' +
	'<li><a href="chapter_004.html#4.6">4.6 - Executive function - deciding between actions</a></li>' +
	'<li><a href="chapter_004.html#4.7">4.7 - Complexity and Invariance</a></li>' +
	'<li><a href="chapter_004.html#4.8">4.8 - Chess versus buying cookies</a></li>' +
	'<li><a href="chapter_004.html#4.9">4.9 - Invariance and context</a></li>' +
	'<li><a href="chapter_004.html#4.10">4.10 - Chess Revisited</a></li>' +
	'<li><a href="chapter_004.html#4.11">4.11 - Artificiality</a></li>' +
	'<li><a href="chapter_004.html#4.12">4.12 - The Chinese Room</a></li>' +
	'<li><a href="chapter_004.html#4.13">4.13 - On ethics, morality, and the singularity</a></li>' +
	'<li><a href="chapter_004.html#4.14">4.14 - References</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">5 - Suggested Readings</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_005.html#5.1">5.1 - Introduction</a></li>' +
	'<li><a href="chapter_005.html#5.2">5.2 - Artificial Intelligence</a></li>' +
	'<li><a href="chapter_005.html#5.3">5.3 - Bias</a></li>' +
	'<li><a href="chapter_005.html#5.4">5.4 - Biology and Cancer</a></li>' +
	'<li><a href="chapter_005.html#5.5">5.5 - Complexity, Dynamical Systems Theory, Chaos Theory</a></li>' +
	'<li><a href="chapter_005.html#5.6">5.6 - Game Design and AI</a></li>' +
	'<li><a href="chapter_005.html#5.7">5.7 - Genetic Algorithms and ABM</a></li>' +
	'<li><a href="chapter_005.html#5.8">5.8 - Graphs and Networks</a></li>' +
	'<li><a href="chapter_005.html#5.9">5.9 - Innovation</a></li>' +
	'<li><a href="chapter_005.html#5.10">5.10 - Machine Learning</a></li>' +
	'<li><a href="chapter_005.html#5.11">5.11 - Mathematics</a></li>' +
	'<li><a href="chapter_005.html#5.12">5.12 - Neural Networks</a></li>' +
	'<li><a href="chapter_005.html#5.13">5.13 - Neuroscience and Psychology</a></li>' +
	'<li><a href="chapter_005.html#5.14">5.14 - Natural Language Processing</a></li>' +
	'<li><a href="chapter_005.html#5.15">5.15 - Non-Fiction</a></li>' +
	'<li><a href="chapter_005.html#5.16">5.16 - Philosophy</a></li>' +
	'<li><a href="chapter_005.html#5.17">5.17 - Programming</a></li>' +
	'<li><a href="chapter_005.html#5.18">5.18 - Quantum Computing</a></li>' +
	'<li><a href="chapter_005.html#5.19">5.19 - Robotics</a></li>' +
	'<li><a href="chapter_005.html#5.20">5.20 - Smart Buildings and IoTs</a></li>' +
	'<li><a href="chapter_005.html#5.21">5.21 - Virtual Reality</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">6 - Data Types</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_006.html#6.1">6.1 – Introduction</a></li>' +
	'<li><a href="chapter_006.html#6.2">6.2 - Numerical Data</a></li>' +
	'<li><a href="chapter_006.html#6.3">6.3 - Categorical Data</a></li>' +
	'<li><a href="chapter_006.html#6.4">6.4 – Scales</a></li>' +
	'<li><a href="chapter_006.html#6.5">6.5 - Mixed Data</a></li>' +
	'<li><a href="chapter_006.html#6.6">6.6 - Event data</a></li>' +
	'<li><a href="chapter_006.html#6.7">6.7 - Timeseries Data</a></li>' +
	'<li><a href="chapter_006.html#6.8">6.8 - Image Data</a></li>' +
	'<li><a href="chapter_006.html#6.9">6.9 - Textual Data</a></li>' +
	'<li><a href="chapter_006.html#6.10">6.10 - Connected Data</a></li>' +
	'<li><a href="chapter_006.html#6.11">6.11 - Speech Data</a></li>' +
	'<li><a href="chapter_006.html#6.12">6.12 - DNA and biological topology Data</a></li>' +
	'<li><a href="chapter_006.html#6.13">6.13 - Other types of data</a></li>' +
	'<li><a href="chapter_006.html#6.14">6.14 - Conclusion</a></li>' +
	'<li><a href="chapter_006.html#6.15">6.15 – References</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">7 - Prior Considerations</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_007.html#7.1">7.1 - Introduction</a></li>' +
	'<li><a href="chapter_007.html#7.2">7.2 - Supervised vs. Unsupervised - The amount of ground truth</a></li>' +
	'<li><a href="chapter_007.html#7.3">7.3 - Categorical, numerical, or something else altogether</a></li>' +
	'<li><a href="chapter_007.html#7.4">7.4 - Black box versus open box</a></li>' +
	'<li><a href="chapter_007.html#7.5">7.5 - Deterministic versus Probabilistic</a></li>' +
	'<li><a href="chapter_007.html#7.6">7.6 - Conclusions</a></li>' +
	'<li><a href="chapter_007.html#7.7">7.7 - References</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">8 - Algorithmic Objectives</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_008.html#8.1">8.1 - Introduction</a></li>' +
	'<li><a href="chapter_008.html#8.2">8.2 - Regression</a></li>' +
	'<li><a href="chapter_008.html#8.3">8.3 - Classification</a></li>' +
	'<li><a href="chapter_008.html#8.4">8.4 - Clustering</a></li>' +
	'<li><a href="chapter_008.html#8.5">8.5 - Manifolds</a></li>' +
	'<li><a href="chapter_008.html#8.6">8.6 - Vectorization</a></li>' +
	'<li><a href="chapter_008.html#8.7">8.7 - Forecasting</a></li>' +
	'<li><a href="chapter_008.html#8.8">8.8 - Link Prediction</a></li>' +
	'<li><a href="chapter_008.html#8.9">8.9 - Recommendation</a></li>' +
	'<li><a href="chapter_008.html#8.10">8.10 - Anomaly Detection</a></li>' +
	'<li><a href="chapter_008.html#8.11">8.11 – Generative Models</a></li>' +
	'<li><a href="chapter_008.html#8.12">8.12 - References</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">9 - A Partial Taxonomy</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_009.html#9.1">9.1 - Introduction</a></li>' +
	'<li><a href="chapter_009.html#9.2">9.2 - Regression Algorithms</a></li>' +
	'<li><a href="chapter_009.html#9.3">9.3 - Classification Algorithms</a></li>' +
	'<li><a href="chapter_009.html#9.4">9.4 - Ensemble Methods</a></li>' +
	'<li><a href="chapter_009.html#9.5">9.5 - Clustering Algorithms</a></li>' +
	'<li><a href="chapter_009.html#9.6">9.6 - Dimensionality Reduction Algorithms</a></li>' +
	'<li><a href="chapter_009.html#9.7">9.7 - Manifold Algorithms</a></li>' +
	'<li><a href="chapter_009.html#9.8">9.8 - Natural Language Processing</a></li>' +
	'<li><a href="chapter_009.html#9.9">9.9 - Graph Algorithms</a></li>' +
	'<li><a href="chapter_009.html#9.10">9.10 - Neural Networks</a></li>' +
	'<li><a href="chapter_009.html#9.11">9.11 - Niche Algorithms</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">10 - Different Perspectives</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_010.html#10.1">10.1 - Introduction</a></li>' +
	'<li><a href="chapter_010.html#10.2">10.2 - Statistical Perspective</a></li>' +
	'<li><a href="chapter_010.html#10.3">10.3 - Algebraic Perspective</a></li>' +
	'<li><a href="chapter_010.html#10.4">10.4 - Calculus perspective</a></li>' +
	'<li><a href="chapter_010.html#10.5">10.5 - Conclusion</a></li>' +
	'<li><a href="chapter_010.html#10.6">10.6 - References</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">11 - The Geometry of Machine Learning</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_011.html#11.1">11.1 - Introduction</a></li>' +
	'<li><a href="chapter_011.html#11.2">11.2 - Preamble</a></li>' +
	'<li><a href="chapter_011.html#11.3">11.3 - Points</a></li>' +
	'<li><a href="chapter_011.html#11.4">11.4 - Vectors</a></li>' +
	'<li><a href="chapter_011.html#11.5">11.5 - Matrices</a></li>' +
	'<li><a href="chapter_011.html#11.6">11.6 - The correct number of rows and columns</a></li>' +
	'<li><a href="chapter_011.html#11.7">11.7 - Formalizing machine learning</a></li>' +
	'<li><a href="chapter_011.html#11.8">11.8 - The Geometry of Machine Learning</a></li>' +
	'<li><a href="chapter_011.html#11.9">11.9 - Conclusion</a></li>' +
	'<li><a href="chapter_011.html#11.10">11.10 - References</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">12 - Transformations</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_012.html#12.1">12.1 – Introduction</a></li>' +
	'<li><a href="chapter_012.html#12.2">12.2 - The Geometry of everyday space</a></li>' +
	'<li><a href="chapter_012.html#12.3">12.3 - The geometry of machine learning data</a></li>' +
	'<li><a href="chapter_012.html#12.4">12.4 - Defining distance</a></li>' +
	'<li><a href="chapter_012.html#12.5">12.5 - Euclidean distance</a></li>' +
	'<li><a href="chapter_012.html#12.6">12.6 - Violations of the Euclidean assumption</a></li>' +
	'<li><a href="chapter_012.html#12.7">12.7 - Unequal Variance</a></li>' +
	'<li><a href="chapter_012.html#12.8">12.8 - Covariance</a></li>' +
	'<li><a href="chapter_012.html#12.9">12.9 - Alternative Distance Metrics</a></li>' +
	'<li><a href="chapter_012.html#12.10">12.10 - Manhattan and Cosine Distance</a></li>' +
	'<li><a href="chapter_012.html#12.11">12.11 - The curse of dimensionality</a></li>' +
	'<li><a href="chapter_012.html#12.12">12.12 - Normalization</a></li>' +
	'<li><a href="chapter_012.html#12.13">12.13 - Categorical Variables</a></li>' +
	'<li><a href="chapter_012.html#12.14">12.14 - Transformations</a></li>' +
	'<li><a href="chapter_012.html#12.15">12.15 - Bias terms and intercepts</a></li>' +
	'<li><a href="chapter_012.html#12.16">12.16 - Translation</a></li>' +
	'<li><a href="chapter_012.html#12.17">12.17 - Rotation</a></li>' +
	'<li><a href="chapter_012.html#12.18">12.18 - Scaling</a></li>' +
	'<li><a href="chapter_012.html#12.19">12.19 - Shear</a></li>' +
	'<li><a href="chapter_012.html#12.20">12.20 - Combining rotations, scaling, shearing, and translations</a></li>' +
	'<li><a href="chapter_012.html#12.21">12.21 - Putting it all together - Mappings</a></li>' +
	'<li><a href="chapter_012.html#12.22">12.22 - Conclusions</a></li>' +
	'<li><a href="chapter_012.html#12.23">12.23 - Demo Notebooks</a></li>' +
	'<li><a href="chapter_012.html#12.24">12.24 - References</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">13 - The Statistics of Machine Learning</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_013.html#13.1">13.1 - Introduction</a></li>' +
	'<li><a href="chapter_013.html#13.2">13.2 - The mean, variance, standard deviation, and covariance</a></li>' +
	'<li><a href="chapter_013.html#13.3">13.3 - The mean</a></li>' +
	'<li><a href="chapter_013.html#13.4">13.4 - Variance</a></li>' +
	'<li><a href="chapter_013.html#13.5">13.5 - Population versus sample variance</a></li>' +
	'<li><a href="chapter_013.html#13.6">13.6 - Standard Deviation</a></li>' +
	'<li><a href="chapter_013.html#13.7">13.7 - Covariance</a></li>' +
	'<li><a href="chapter_013.html#13.8">13.8 - Probability Distributions</a></li>' +
	'<li><a href="chapter_013.html#13.9">13.9 - The Normal Distribution</a></li>' +
	'<li><a href="chapter_013.html#13.10">13.10 - Joint distributions – IQ and temperature</a></li>' +
	'<li><a href="chapter_013.html#13.11">13.11 - Joint distributions – IQ and maternal IQ</a></li>' +
	'<li><a href="chapter_013.html#13.12">13.12 - Dependencies</a></li>' +
	'<li><a href="chapter_013.html#13.13">13.13 - Other statistical distributions</a></li>' +
	'<li><a href="chapter_013.html#13.14">13.14 - Conclusions</a></li>' +
	'<li><a href="chapter_013.html#13.15">13.15 – Demo Notebooks</a></li>' +
	'<li><a href="chapter_013.html#13.16">13.16 - References</a></li>' +
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="#">14 - Regression</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_014.html#14.1">14.1 - Introduction' + 
	'<li><a href="chapter_014.html#14.2">14.2 - Why this is probably the most important chapter in this course' + 
	'<li><a href="chapter_014.html#14.3">14.3 – Getting started with linear regression' + 
	'<li><a href="chapter_014.html#14.4">14.4 - Nomenclature - Weights, parameters and hyperparameters' + 
	'<li><a href="chapter_014.html#14.5">14.5 - Nomenclature - Variables, regressors and predictors' + 
	'<li><a href="chapter_014.html#14.6">14.6 - Data exploration - Medical Expense Dataset' + 
	'<li><a href="chapter_014.html#14.7">14.7 - A subset of the data' + 
	'<li><a href="chapter_014.html#14.8">14.8 – Manual Tuning' + 
	'<li><a href="chapter_014.html#14.9">14.9 – Defining our model' + 
	'<li><a href="chapter_014.html#14.10">14.10 - Quantifying performance' + 
	'<li><a href="chapter_014.html#14.11">14.11 - The intuition behind the R-squared metric' + 
	'<li><a href="chapter_014.html#14.12">14.12 - SST, SSE, SSR' + 
	'<li><a href="chapter_014.html#14.13">14.13 - Coefficient of determination or r-squared' + 
	'<li><a href="chapter_014.html#14.14">14.14 - A quick word of caution' + 
	'<li><a href="chapter_014.html#14.15">14.15 – Our very first regression model' + 
	'<li><a href="chapter_014.html#14.16">14.16 – Improving performance - introducing a positive slope' + 
	'<li><a href="chapter_014.html#14.17">14.17 - Improving performance - an empirical constraint' + 
	'<li><a href="chapter_014.html#14.18">14.18 – Improving performance - close to ideal' + 
	'<li><a href="chapter_014.html#14.19">14.19 - R-squared vs Correlations' + 
	'<li><a href="chapter_014.html#14.20">14.20 - It is only model' + 
	'<li><a href="chapter_014.html#14.21">14.21 - Estimating parameters algorithmically' + 
	'<li><a href="chapter_014.html#14.22">14.22 - Closed Form versus Iterative Methods' + 
	'<li><a href="chapter_014.html#14.23">14.23 - Error' + 
	'<li><a href="chapter_014.html#14.24">14.24 - Turning Error into Loss' + 
	'<li><a href="chapter_014.html#14.25">14.25 - Loss Landscapes' + 
	'<li><a href="chapter_014.html#14.26">14.26 - Statistical estimates for our parameters a and b' + 
	'<li><a href="chapter_014.html#14.27">14.27 - Beyond a single input variable' + 
	'<li><a href="chapter_014.html#14.28">14.28 - The Algebraic Approach - Ordinary Least Squares' + 
	'<li><a href="chapter_014.html#14.29">14.29 - From element and lists to vectors and matrices' + 
	'<li><a href="chapter_014.html#14.30">14.30 - Ordinary Least Squares' + 
	'<li><a href="chapter_014.html#14.31">14.31 - OLS on the medical expense dataset' + 
	'<li><a href="chapter_014.html#14.32">14.32 - More than just a succinct algebraic solution' + 
	'<li><a href="chapter_014.html#14.33">14.33 - Introduction to gradient descent' + 
	'<li><a href="chapter_014.html#14.34">14.34 - Getting all our ducks in a row' + 
	'<li><a href="chapter_014.html#14.35">14.35 - Loss Landscapes Revisited' + 
	'<li><a href="chapter_014.html#14.36">14.36 - Descending the Scottish Highlands' + 
	'<li><a href="chapter_014.html#14.37">14.37 - Getting stuck' + 
	'<li><a href="chapter_014.html#14.38">14.38 - Computing the gradient' + 
	'<li><a href="chapter_014.html#14.39">14.39 - Computing the gradient - 1D Example' + 
	'<li><a href="chapter_014.html#14.40">14.40 - Computing the gradient - 2D Example' + 
	'<li><a href="chapter_014.html#14.41">14.41 - Learning Rates and Convergence' + 
	'<li><a href="chapter_014.html#14.42">14.42 - The Gradient Descent Algorithm' + 
	'<li><a href="chapter_014.html#14.43">14.43 - Initial Parameters' + 
	'<li><a href="chapter_014.html#14.44">14.44 - Different Training Regimes' + 
	'<li><a href="chapter_014.html#14.45">14.45 - Stochastic Gradient Descent' + 
	'<li><a href="chapter_014.html#14.46">14.46 - Batch Gradient Descent' + 
	'<li><a href="chapter_014.html#14.47">14.47 - Hyperparameters' + 
	'<li><a href="chapter_014.html#14.48">14.48 - Overfitting and Underfitting' + 
	'<li><a href="chapter_014.html#14.49">14.49 - Conclusions' + 
	'<li><a href="chapter_014.html#14.50">14.50 - Demo Notebooks and Playgrounds' + 
	'<li><a href="chapter_014.html#14.51">14.51 – References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">15 - Classification</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_015.html#15.1">15.1 - Introduction' + 
	'<li><a href="chapter_015.html#15.2">15.2 - A new activation function' + 
	'<li><a href="chapter_015.html#15.3">15.3 – A new loss function' + 
	'<li><a href="chapter_015.html#15.4">15.4 - Introducing Logistic Regression' + 
	'<li><a href="chapter_015.html#15.5">15.5 - Measures of success' + 
	'<li><a href="chapter_015.html#15.6">15.6 - Measures of success - When accuracy falls short' + 
	'<li><a href="chapter_015.html#15.7">15.7 - Measures of success - False, True, Negative and Positive' + 
	'<li><a href="chapter_015.html#15.8">15.8 - Precision and recall' + 
	'<li><a href="chapter_015.html#15.9">15.9 - F-Scores' + 
	'<li><a href="chapter_015.html#15.10">15.10 – Area under the ROC curve' + 
	'<li><a href="chapter_015.html#15.11">15.11 - Underfitting and Overfitting' + 
	'<li><a href="chapter_015.html#15.12">15.12 - Imbalanced classes' + 
	'<li><a href="chapter_015.html#15.13">15.13 - Multiclass problems' + 
	'<li><a href="chapter_015.html#15.14">15.14 - Other Classification Algorithms' + 
	'<li><a href="chapter_015.html#15.15">15.15 - Conclusion' + 
	'<li><a href="chapter_015.html#15.16">15.16 - Demo Notebooks' + 
	'<li><a href="chapter_015.html#15.17">15.17 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">16 - Decision Trees</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_016.html#16.1">16.1 – Introduction' + 
	'<li><a href="chapter_016.html#16.2">16.2 - Pros and cons of Decision Trees' + 
	'<li><a href="chapter_016.html#16.3">16.3 – Gini Impurity Index - Theory' + 
	'<li><a href="chapter_016.html#16.4">16.4 – Gini Impurity Index - Example' + 
	'<li><a href="chapter_016.html#16.5">16.5 – Gini Gain - Party Game Example' + 
	'<li><a href="chapter_016.html#16.6">16.6 – Gini Gain - Synthetic Cancer Risk Data' + 
	'<li><a href="chapter_016.html#16.7">16.7 – Gini Gain - Finding the best split within a variable' + 
	'<li><a href="chapter_016.html#16.8">16.8 - Entropy and Information Theory' + 
	'<li><a href="chapter_016.html#16.9">16.9 - A deeper relationship between information and physical reality' + 
	'<li><a href="chapter_016.html#16.10">16.10 - Information Gain in decision trees' + 
	'<li><a href="chapter_016.html#16.11">16.11 - Building the decision tree' + 
	'<li><a href="chapter_016.html#16.12">16.12 - Pruning' + 
	'<li><a href="chapter_016.html#16.13">16.13 - Pruning by information gain' + 
	'<li><a href="chapter_016.html#16.14">16.14 - Reduced Error Pruning (REP)' + 
	'<li><a href="chapter_016.html#16.15">16.15 - Cost-complexity pruning' + 
	'<li><a href="chapter_016.html#16.16">16.16 - Combining decision trees - Random Forests' + 
	'<li><a href="chapter_016.html#16.17">16.17 – Conclusions' + 
	'<li><a href="chapter_016.html#16.18">16.18 - Notebooks' + 
	'<li><a href="chapter_016.html#16.19">16.19 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">17 - Clustering</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_017.html#17.1">17.1 - Introduction' + 
	'<li><a href="chapter_017.html#17.2">17.2 – A Geometric Interpretation' + 
	'<li><a href="chapter_017.html#17.3">17.3 – Distance revisited' + 
	'<li><a href="chapter_017.html#17.4">17.4 - Clustering Methodologies' + 
	'<li><a href="chapter_017.html#17.5">17.5 - Expectation Maximization - Theory' + 
	'<li><a href="chapter_017.html#17.6">17.6 - Expectation Maximization - Practice' + 
	'<li><a href="chapter_017.html#17.7">17.7 - Distance Based Clustering - K-means' + 
	'<li><a href="chapter_017.html#17.8">17.8 - The Birth of Epidemiology' + 
	'<li><a href="chapter_017.html#17.9">17.9 - K-means pseudo code walkthrough' + 
	'<li><a href="chapter_017.html#17.10">17.10 - Metrics of success' + 
	'<li><a href="chapter_017.html#17.11">17.11 - Silhouette Metric' + 
	'<li><a href="chapter_017.html#17.12">17.12 - Choosing K to be the right number of clusters' + 
	'<li><a href="chapter_017.html#17.13">17.13 - Choosing K - edge case 1 - Randomness' + 
	'<li><a href="chapter_017.html#17.14">17.14 - Choosing K - edge case 2 - Perfection to chaos' + 
	'<li><a href="chapter_017.html#17.15">17.15 - What is good for the goose is good for the gander' + 
	'<li><a href="chapter_017.html#17.16">17.16 - Limitations of Distance Based Clustering Methods' + 
	'<li><a href="chapter_017.html#17.17">17.17 - Distribution Based Clustering - Gaussian Mixture Models' + 
	'<li><a href="chapter_017.html#17.18">17.18 - GMM pseudo code walkthrough' + 
	'<li><a href="chapter_017.html#17.19">17.19 - Density Based Clustering - DBSCAN' + 
	'<li><a href="chapter_017.html#17.20">17.20 - Other clusters algorithms - Hierarchical Clustering' + 
	'<li><a href="chapter_017.html#17.21">17.21 - Conclusion' + 
	'<li><a href="chapter_017.html#17.22">17.22 - Notebooks' + 
	'<li><a href="chapter_017.html#17.23">17.23 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">18 - Dimensionality Reduction</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_018.html#18.1">18.1 - Introduction' + 
	'<li><a href="chapter_018.html#18.2">18.2 - Introducing subspaces' + 
	'<li><a href="chapter_018.html#18.3">18.3 - Decreasing computational complexity' + 
	'<li><a href="chapter_018.html#18.4">18.4 - Known underlying signals' + 
	'<li><a href="chapter_018.html#18.5">18.6 - The allgory of Platos cave' + 
	'<li><a href="chapter_018.html#18.6">18.7 - Diving into the ocean' + 
	'<li><a href="chapter_018.html#18.7">18.8 - The epidemiology of cancer' + 
	'<li><a href="chapter_018.html#18.8">18.8 – The heart of PCA' + 
	'<li><a href="chapter_018.html#18.9">18.9 – Points as vectors' + 
	'<li><a href="chapter_018.html#18.10">18.10 - Flatland' + 
	'<li><a href="chapter_018.html#18.11">18.11 - IndependenceWorld' + 
	'<li><a href="chapter_018.html#18.12">18.12 - Color as useful an analogy' + 
	'<li><a href="chapter_018.html#18.13">18.13 - Reversing the Process' + 
	'<li><a href="chapter_018.html#18.14">18.14 - Is there life on Mars?' + 
	'<li><a href="chapter_018.html#18.15">18.15 - Eigenvalues and Eigenvectors' + 
	'<li><a href="chapter_018.html#18.16">18.16 – Singular Value Decomposition' + 
	'<li><a href="chapter_018.html#18.17">18.17 – Combining all ideas into a single framework: using PCA in practice' + 
	'<li><a href="chapter_018.html#18.18">18.18 – PCA - eigenfaces' + 
	'<li><a href="chapter_018.html#18.19">18.19 – ICA - Source Seperation' + 
	'<li><a href="chapter_018.html#18.20">18.20 – Basis Functions - Heart Rates' + 
	'<li><a href="chapter_018.html#18.21">18.21 – Basis Functions - Fast Fourier Transform' + 
	'<li><a href="chapter_018.html#18.22">18.22 – Basis Functions - JPEG Compression using DCT' + 
	'<li><a href="chapter_018.html#18.23">18.23 - Beyond linear constraints - Autoencoders' + 
	'<li><a href="chapter_018.html#18.24">18.24 - Discussion' + 
	'<li><a href="chapter_018.html#18.25">18.25 - Notebooks' + 
	'<li><a href="chapter_018.html#18.26">18.26 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">19 - Manifolds</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_019.html#19.1">19.1 - Introduction' + 
	'<li><a href="chapter_019.html#19.2">19.2 - Color perception as an example of a true manifold' + 
	'<li><a href="chapter_019.html#19.3">19.3 - Newtowns Mistake' + 
	'<li><a href="chapter_019.html#19.4">19.4 - Wavelength does not equal perceived color' + 
	'<li><a href="chapter_019.html#19.5">19.5 - The dimensions of color vision - luminance' + 
	'<li><a href="chapter_019.html#19.6">19.6 - The dimensions of color vision - saturation' + 
	'<li><a href="chapter_019.html#19.7">19.7 - The dimensions of color vision - hue' + 
	'<li><a href="chapter_019.html#19.8">19.8 - Representing color on a screen' + 
	'<li><a href="chapter_019.html#19.9">19.9 - Representing color in the mind' + 
	'<li><a href="chapter_019.html#19.10">19.10 - The manifold of hue and saturation in RGB space' + 
	'<li><a href="chapter_019.html#19.11">19.11 - Relationship with other algorithm objectives' + 
	'<li><a href="chapter_019.html#19.12">19.12 - Faces as an example' + 
	'<li><a href="chapter_019.html#19.13">19.13 - Notebooks' + 
	'<li><a href="chapter_019.html#19.14">19.14 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">20 - Graphs</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_020.html#20.1">20.1 - Introduction' + 
	'<li><a href="chapter_020.html#20.2">20.2 - Graph or network?' + 
	'<li><a href="chapter_020.html#20.3">20.3 - Applications of graph theory' + 
	'<li><a href="chapter_020.html#20.4">20.4 - Erdos, Natalie Portman, Kevin Bacon' + 
	'<li><a href="chapter_020.html#20.5">20.5 - Toolbox Use' + 
	'<li><a href="chapter_020.html#20.6">20.6 - Graph essentials' + 
	'<li><a href="chapter_020.html#20.7">20.7 - Degree' + 
	'<li><a href="chapter_020.html#20.8">20.8 - Centrality' + 
	'<li><a href="chapter_020.html#20.9">20.9 - Degree centrality' + 
	'<li><a href="chapter_020.html#20.10">20.10 - Betweenness centrality' + 
	'<li><a href="chapter_020.html#20.11">20.11 – PageRank' + 
	'<li><a href="chapter_020.html#20.12">20.12 – PageRank Revisited' + 
	'<li><a href="chapter_020.html#20.13">20.13 – Path finding and search' + 
	'<li><a href="chapter_020.html#20.14">20.14 – Depth First Search' + 
	'<li><a href="chapter_020.html#20.15">20.15 – Breadth First Search' + 
	'<li><a href="chapter_020.html#20.16">20.16 – Dijkstra’s Shortest Path Algorithm' + 
	'<li><a href="chapter_020.html#20.17">20.17 – Community Detection - Theory' + 
	'<li><a href="chapter_020.html#20.18">20.18 – Community Detection - Algorithms' + 
	'<li><a href="chapter_020.html#20.19">20.19 – Link Prediction - Theory' + 
	'<li><a href="chapter_020.html#20.20">20.20 - Link prediction - Algorithms' + 
	'<li><a href="chapter_020.html#20.21">20.21 - Conclusion' + 
	'<li><a href="chapter_020.html#20.22">20.22 - Notebooks' + 
	'<li><a href="chapter_020.html#20.23">20.23 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">21 - Natural Language Processing</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_021.html#21.1">21.1 - Introduction' + 
	'<li><a href="chapter_021.html#21.2">21.2 - Use Cases - Text classification' + 
	'<li><a href="chapter_021.html#21.3">21.3 - Use Cases - Translation' + 
	'<li><a href="chapter_021.html#21.4">21.4 - Use Cases - Topic modeling' + 
	'<li><a href="chapter_021.html#21.5">21.5 - Use Cases - Text Summarization' + 
	'<li><a href="chapter_021.html#21.6">21.6 – Use Cases - Entity resolution' + 
	'<li><a href="chapter_021.html#21.7">21.7 – Use Cases - Knowledge graphs' + 
	'<li><a href="chapter_021.html#21.8">21.8 – Use Cases - Text Synthesis' + 
	'<li><a href="chapter_021.html#21.9">21.9 – Use Cases - Spelling and grammar' + 
	'<li><a href="chapter_021.html#21.10">21.10 – Use Cases - Word2Vector' + 
	'<li><a href="chapter_021.html#21.11">21.11 - Preprocessing' + 
	'<li><a href="chapter_021.html#21.12">21.12 - Stemming and Lemmatization' + 
	'<li><a href="chapter_021.html#21.13">21.13 - Stopword Removal' + 
	'<li><a href="chapter_021.html#21.14">21.14 - Bag of Words versus Generative and Probabilistic Models' + 
	'<li><a href="chapter_021.html#21.15">21.15 - Bag of Words - Topic Modeling' + 
	'<li><a href="chapter_021.html#21.16">21.16 - Bag of Words - Topic Modeling - TFiDF' + 
	'<li><a href="chapter_021.html#21.17">21.17 - Bag of Words - Topic Modeling - LDA' + 
	'<li><a href="chapter_021.html#21.18">21.18 – Probability algorithms – Intro to Bayes law' + 
	'<li><a href="chapter_021.html#21.19">21.19 – Probability algorithms – Naive Bayes Classifiers' + 
	'<li><a href="chapter_021.html#21.20">21.20 – Word2Vec' + 
	'<li><a href="chapter_021.html#21.21">21.21 – Notebooks' + 
	'<li><a href="chapter_021.html#21.22">21.22 – References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">22 - Causal Inference</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_022.html#22.1">22.1 - Introduction' + 
	'<li><a href="chapter_022.html#22.2">22.2 - Correlation does not imply causation' + 
	'<li><a href="chapter_022.html#22.3">22.3 - Directed Acyclic Graphs' + 
	'<li><a href="chapter_022.html#22.4">22.4 - Propensity score matching' + 
	'<li><a href="chapter_022.html#22.5">22.5 - Notebooks' + 
	'<li><a href="chapter_022.html#22.6">22.6 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">23 - Introduction to Neural Networks</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_023.html#23.1">23.1 - Introduction' + 
	'<li><a href="chapter_023.html#23.2">23.2 - Biological Neural Networks' + 
	'<li><a href="chapter_023.html#23.3">23.3 - The Neuron' + 
	'<li><a href="chapter_023.html#23.4">23.4 - Pathways and centers' + 
	'<li><a href="chapter_023.html#23.5">23.5 - ANNs as Abstractions' + 
	'<li><a href="chapter_023.html#23.6">23.6 - Versatility vs. the kitchen sink' + 
	'<li><a href="chapter_023.html#23.7">23.7 - Scalability versus a loss of insight' + 
	'<li><a href="chapter_023.html#23.8">23.8 - Flexibility versus bias' + 
	'<li><a href="chapter_023.html#23.9">23.9 - The Quick History of ANNs' + 
	'<li><a href="chapter_023.html#23.10">23.10 - Conclusion' + 
	'<li><a href="chapter_023.html#23.11">23.11 – Demo Notebooks' + 
	'<li><a href="chapter_023.html#23.12">23.12 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">24 - Building your First Artificial Neural Network</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_024.html#24.1">24.1 - Introduction' + 
	'<li><a href="chapter_024.html#24.2">24.2 – Definitions' + 
	'<li><a href="chapter_024.html#24.3">24.3 – Building an AND logic gate' + 
	'<li><a href="chapter_024.html#24.4">24.4 – The Perceptron' + 
	'<li><a href="chapter_024.html#24.5">24.5 – AND, OR, and NOT gates revisited' + 
	'<li><a href="chapter_024.html#24.6">24.6 - Rosenblatt’s Perceptron learning rule' + 
	'<li><a href="chapter_024.html#24.7">24.7 - Perceptron Training - Initialization' + 
	'<li><a href="chapter_024.html#24.8">24.8 - Perceptron Training - Compute Activation and Output' + 
	'<li><a href="chapter_024.html#24.9">24.9 - Perceptron Training - Compute the error' + 
	'<li><a href="chapter_024.html#24.10">24.10 - Perceptron Training - Update the weights' + 
	'<li><a href="chapter_024.html#24.11">24.11 - Perceptron Training - Convergence and halt' + 
	'<li><a href="chapter_024.html#24.12">24.12 - Activation Functions' + 
	'<li><a href="chapter_024.html#24.13">24.13 - An innovation with a darker side' + 
	'<li><a href="chapter_024.html#24.14">24.14 - Biological vs. Artificial Neural Networks, revisited' + 
	'<li><a href="chapter_024.html#24.15">24.15 - Demo notebooks' + 
	'<li><a href="chapter_024.html#24.16">24.16 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">25 - Multilayer Neural Networks</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_025.html#25.1">25.1 - Introduction' + 
	'<li><a href="chapter_025.html#25.2">25.2 - Minsky and Paperts monkey wrench' + 
	'<li><a href="chapter_025.html#25.3">25.3 - Enter Backpropagation' + 
	'<li><a href="chapter_025.html#25.4">25.4 - Backpropagation in a nutshell' + 
	'<li><a href="chapter_025.html#25.5">25.4 - Scikit-learn' + 
	'<li><a href="chapter_025.html#25.6">25.5 - The XOR Problem revisited' + 
	'<li><a href="chapter_025.html#25.7">25.6 - 2-layer neural network and linear regression' + 
	'<li><a href="chapter_025.html#25.8">25.7 - Testing for linear seperability' + 
	'<li><a href="chapter_025.html#25.9">25.8 - 2-layer Perceptrons with a linear activation function' + 
	'<li><a href="chapter_025.html#25.10">25.9 - Non-linear activation functions' + 
	'<li><a href="chapter_025.html#25.11">25.10 - Linear, Tanh and Sigmoid activation functions' + 
	'<li><a href="chapter_025.html#25.12">25.11 - Multi-Layer neural networks with linear activation functions' + 
	'<li><a href="chapter_025.html#25.13">25.12 - A Multi-layer perceptron with strictly linear acitivation functions' + 
	'<li><a href="chapter_025.html#25.14">25.13 - Multlayer neural network with non-linear activiation functions' + 
	'<li><a href="chapter_025.html#25.14">25.14 - Predicting Breast Cancer Risk' + 
	'<li><a href="chapter_025.html#25.15">25.15 - Predicting Genre from Spotify Audio Features' + 
	'<li><a href="chapter_025.html#25.16">25.16 - Conclusion' + 
	'<li><a href="chapter_025.html#25.17">25.17 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">26 - Deep Belief Neural Networks</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_026.html#26.1">26.1 - Introduction' + 
	'<li><a href="chapter_026.html#26.2">26.2 - (Leaky) ReLu activation functions' + 
	'<li><a href="chapter_026.html#26.3">26.3 - Optimization and Learning' + 
	'<li><a href="chapter_026.html#26.4">26.4 - Optimization and Learning - AdaGrad and RMSProp' + 
	'<li><a href="chapter_026.html#26.5">26.5 - Optimization and Learning - Adam' + 
	'<li><a href="chapter_026.html#26.6">26.6 - Optimization and Learning - Other optimizers' + 
	'<li><a href="chapter_026.html#26.7">26.7 - Dropout' + 
	'<li><a href="chapter_026.html#26.8">26.8 - Introduction into Tensorflow' + 
	'<li><a href="chapter_026.html#26.9">26.9 - Building a our first TensorFlow model' + 
	'<li><a href="chapter_026.html#26.10">26.10 - Tensorflow linear regression - Synthentic Data' + 
	'<li><a href="chapter_026.html#26.11">26.11 - Tensorflow linear regression - Numpy to Tensorflow' + 
	'<li><a href="chapter_026.html#26.12">26.12 - Tensorflow linear regression - Model Specification' + 
	'<li><a href="chapter_026.html#26.13">26.13 - Tensorflow linear regression - Optimizer' + 
	'<li><a href="chapter_026.html#26.14">26.14 - Tensorflow linear regression - Compile and summarize' + 
	'<li><a href="chapter_026.html#26.15">26.15 - Tensorflow linear regression - Fit and predict' + 
	'<li><a href="chapter_026.html#26.16">26.16 - Multiclass Classification Loss' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">27 - Introduction to Biological Vision</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_027.html#27.1">27.1 - Introduction' + 
	'<li><a href="chapter_027.html#27.2">27.2 - The Retina' + 
	'<li><a href="chapter_027.html#27.3">27.3 - The visual field and what you think you see but do not' + 
	'<li><a href="chapter_027.html#27.4">27.4 - Lateral Geniculate Nucleus' + 
	'<li><a href="chapter_027.html#27.5">27.5 - Primary Visual Cortex – Individual neurons' + 
	'<li><a href="chapter_027.html#27.6">27.6 - Primary Visual Cortex – Organization' + 
	'<li><a href="chapter_027.html#27.7">27.7 - Beyond the Primary Visual Cortex' + 
	'<li><a href="chapter_027.html#27.8">27.8 – Conclusion' + 
	'<li><a href="chapter_027.html#27.9">27.9 - Demo notebooks' + 
	'<li><a href="chapter_027.html#27.10">27.10 – References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">28 - Convolutional Neural Networks</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_028.html#28.1">28.1 - Introduction' + 
	'<li><a href="chapter_028.html#28.2">28.2 - Introduction to Convolution' + 
	'<li><a href="chapter_028.html#28.3">28.3 - Convolution versus Cross-Correlation' + 
	'<li><a href="chapter_028.html#28.4">28.4 - Convolution explained - 1D time series - example 1' + 
	'<li><a href="chapter_028.html#28.5">28.5 - Convolution explained - 1D time series - example 2' + 
	'<li><a href="chapter_028.html#28.6">28.6 - 2D Convolution on images - Sobel Filter' + 
	'<li><a href="chapter_028.html#28.7">28.7 - 2D Convolution on images - Orientation Tuning' + 
	'<li><a href="chapter_028.html#28.8">28.8 - Convolutional Layers in cDBNNs' + 
	'<li><a href="chapter_028.html#28.9">28.9 - Layers upon Layers' + 
	'<li><a href="chapter_028.html#28.10">28.10 - Why convolution is such a powerful concept' + 
	'<li><a href="chapter_028.html#28.11">28.11 - Statistics of Natural Images' + 
	'<li><a href="chapter_028.html#28.12">28.12 - Efficiency' + 
	'<li><a href="chapter_028.html#28.13">28.13 - Transfer Learning' + 
	'<li><a href="chapter_028.html#28.14">28.14 - Our first convolutional neural network' + 
	'<li><a href="chapter_028.html#28.15">28.15 - Convolution Stage - Layer 1' + 
	'<li><a href="chapter_028.html#28.16">28.16 - MaxPooling Stage - Layer 1' + 
	'<li><a href="chapter_028.html#28.17">28.17 - Convolution Stage - Layer 2' + 
	'<li><a href="chapter_028.html#28.18">28.18 - MaxPooling Stage - Layer 2' + 
	'<li><a href="chapter_028.html#28.19">28.19 - Convolution Stage - Layer 3' + 
	'<li><a href="chapter_028.html#28.20">28.20 - Dense Layers 4 and 5' + 
	'<li><a href="chapter_028.html#28.21">28.21 - Training the LeNet architecture on the MNIST and CIFAR10 Data' + 
	'<li><a href="chapter_028.html#28.22">28.22 - AlexNet Architecture' + 
	'<li><a href="chapter_028.html#28.23">28.23 - AlexNet - Small Scale' + 
	'<li><a href="chapter_028.html#28.24">28.24 - AlexNet - Full Scale - CPU vs GPU' + 
	'<li><a href="chapter_028.html#28.25">28.25 - Transfer Learning' + 
	'<li><a href="chapter_028.html#28.26">26.26 - Discussion' + 
	'<li><a href="chapter_028.html#28.27">28.27 - Notebooks and Demos' + 
	'<li><a href="chapter_028.html#28.28">28.28 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">29 - Visualizing cDBNNs </a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_029.html#29.1">29.1 - Introduction' + 
	'<li><a href="chapter_029.html#29.2">29.2 - Representations' + 
	'<li><a href="chapter_029.html#29.3">29.3 - Visualizing Neural Networks using Tensorflow Lucid' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">30 - Generative Neural Networks</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_030.html#30.1">30.1 - Introduction' + 
	'<li><a href="chapter_030.html#30.2">30.2 - Creating somehing from nothing' + 
	'<li><a href="chapter_030.html#30.3">30.3 - Auto-encoders' + 
	'<li><a href="chapter_030.html#30.4">30.4 - Bottlenecks' + 
	'<li><a href="chapter_030.html#30.5">30.5 - Compression, reconstruction and denoising' + 
	'<li><a href="chapter_030.html#30.6">30.6 - Segmentation' + 
	'<li><a href="chapter_030.html#30.7">30.7 - Synethesis' + 
	'<li><a href="chapter_030.html#30.8">30.8 - Convolutional Auto-encoders' + 
	'<li><a href="chapter_030.html#30.9">30.9 - Generative Adverserial Neural Networks' + 
	'<li><a href="chapter_030.html#30.10">30.10 - Neural Style Transfer' + 
	'<li><a href="chapter_030.html#30.11">30.11 - Deep dreaming' + 
	'<li><a href="chapter_030.html#30.12">30.12 - Conclusion' + 
	'<li><a href="chapter_030.html#30.13">30.13 - Notebooks' + 
	'<li><a href="chapter_030.html#30.14">30.14 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">31 - Beyond</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_031.html#31.1">31.1 - Introduction' + 
	'<li><a href="chapter_031.html#31.2">31.2 - Reinforcement Learning' + 
	'<li><a href="chapter_031.html#31.3">31.3 - Playing Games - Space Invaders' + 
	'<li><a href="chapter_031.html#31.4">31.4 - Genetic and Evolutionary Algorithms' + 
	'<li><a href="chapter_031.html#31.5">31.5 - Travelling Salesman' + 
	'<li><a href="chapter_031.html#31.6">31.6 - Efficient Nanobots' + 
	'<li><a href="chapter_031.html#31.7">31.7 - Genetic Algorithms for Protein Folding' + 
	'<li><a href="chapter_031.html#31.8">31.8 - Agent-Based Modeling' + 
	'<li><a href="chapter_031.html#31.9">31.9 - Agent-Based Modeling - ABM aided Design' + 
	'<li><a href="chapter_031.html#31.10">31.10 - Agent-Based Modeling - Game of Life' + 
	'<li><a href="chapter_031.html#31.11">31.11 - Agent-Based Modeling - Flocking' + 
	'<li><a href="chapter_031.html#31.12">31.12 - Agent-Based Modeling - Segregation' + 
	'<li><a href="chapter_031.html#31.13">31.13 - Agent-Based Modeling - Evacuation Model' + 
	'<li><a href="chapter_031.html#31.14">31.14 - Agent-Based Modeling - Designing an ICU' + 
	'<li><a href="chapter_031.html#31.15">31.15 - Combining Aprroaches' + 
	'<li><a href="chapter_031.html#31.16">31.16 - Quantum Computing' + 
	'<li><a href="chapter_031.html#31.17">31.17 - Conclusions' + 
	'<li><a href="chapter_031.html#31.18">31.18 - Notebooks' + 
	'<li><a href="chapter_031.html#31.19">31.19 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">32 - Ethics and Bias</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_032.html#32.1">32.1 - Introduction' + 
	'<li><a href="chapter_032.html#32.2">32.2 - Hidden algorithms rather than robots' + 
	'<li><a href="chapter_032.html#32.3">32.3 - Privacy, Fairness, Interpretability, Accountability' + 
	'<li><a href="chapter_032.html#32.4">32.4 - Differential Privacy' + 
	'<li><a href="chapter_032.html#32.5">32.5 - Fairness and bias' + 
	'<li><a href="chapter_032.html#32.6">32.6 - Origins of Bias - Reporting Bias' + 
	'<li><a href="chapter_032.html#32.7">32.7 - Origins of Bias - Selection Bias' + 
	'<li><a href="chapter_032.html#32.8">32.8 - Origins of Bias - Group Attribution Bias' + 
	'<li><a href="chapter_032.html#32.9">32.9 - Origins of Bias - Implicit Bias' + 
	'<li><a href="chapter_032.html#32.10">32.10 - Interpretability' + 
	'<li><a href="chapter_032.html#32.11">32.11 - Accountability - ethics and morality' + 
	'<li><a href="chapter_032.html#32.12">32.12 - Feedback loops and echo chambers' + 
	'<li><a href="chapter_032.html#32.13">32.13 - The social limits of privacy' + 
	'<li><a href="chapter_032.html#32.14">32.14 - Adversial Attacks' + 
	'<li><a href="chapter_032.html#32.15">32.15 - Conclusion' + 
	'<li><a href="chapter_032.html#32.16">32.16 - Notebooks' + 
	'<li><a href="chapter_032.html#32.17">32.17 - References' + 
	'</ul>' +
	'</li>');

toc_content.push(
	'<li>' +
	'<a href="">33 - Final remarks and a Look Forward</a>' +
	'<ul class="nolist">' +
	'<li><a href="chapter_033.html#33.1">33.1 - Conclusion' + 
	'</ul>' +
	'</li>');







